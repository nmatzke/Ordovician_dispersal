i=1
timebin = timebin_borders[i]#
	TF1 = timebin <= obj$rtb$top#
	TF2 = timebin > obj$rtb$top#
	TF = (TF1 + TF2) == 2#
	spRates[i] = obj$rtb$esSp[TF]#
	exRates[i] = obj$rtb$esEx[TF]#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = m_slope * timebin + b_intercept#
		} # END if (sum(TF) > 0)
i
i=2
timebin = timebin_borders[i]#
	TF1 = timebin <= obj$rtb$top#
	TF2 = timebin > obj$rtb$top#
	TF = (TF1 + TF2) == 2#
	spRates[i] = obj$rtb$esSp[TF]#
	exRates[i] = obj$rtb$esEx[TF]
timebin <= obj$rtb$top
timebin
obj$rtb$top
timebin > obj$rtb$top
timebin
obj$rtb$top
TF1 = timebin <= obj$rtb$top
TF1
num1 = max((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = min((1:length(obj$rtb$top))[TF2])
TF2
num1
num2
TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num1#
		num2
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
#
# calcLik_given_known_diversity#
#
# Make total list of timepoints for diversity curve likelihood#
timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
timebin_borders#
#
# Rates for each timebin#
numrates = length(timebin_borders)-1#
spRates = rep(NA, numrates)#
exRates = rep(NA, numrates)#
spDiv = rep(NA, numrates)#
for (i in 1:numrates)#
	{#
	timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top#
	if (sum(TF) > 0)#
		{#
		spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]#
		} else {#
		TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num = min(c(num1, num2))#
		spRates[i] = obj$rtb$esSp[num]#
		exRates[i] = obj$rtb$esEx[num]		#
		} # END if (sum(TF) > 0)#
	TF1 = timebin <= obj$rtb$top#
	TF2 = timebin > obj$rtb$top#
	TF = (TF1 + TF2) == 2#
	spRates[i] = obj$rtb$esSp[TF]#
	exRates[i] = obj$rtb$esEx[TF]#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = m_slope * timebin + b_intercept#
		} # END if (sum(TF) > 0)#
	}#
#
# (currently estimated) diversity and rates#
diversities_rates_table = cbind(timebin_borders, spRates, exRates, spDiv)#
diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
names(diversities_rates_table) = c("timebin_borders", "spRates", "exRates", "spDiv")#
diversities_rates_table
i
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
#
# calcLik_given_known_diversity#
#
# Make total list of timepoints for diversity curve likelihood#
timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
timebin_borders#
#
# Rates for each timebin#
numrates = length(timebin_borders)-1#
spRates = rep(NA, numrates)#
exRates = rep(NA, numrates)#
spDiv = rep(NA, numrates)
i
timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top
TF
spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
#
# calcLik_given_known_diversity#
#
# Make total list of timepoints for diversity curve likelihood#
timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
timebin_borders#
#
# Rates for each timebin#
numrates = length(timebin_borders)-1#
spRates = rep(NA, numrates)#
exRates = rep(NA, numrates)#
spDiv = rep(NA, numrates)#
for (i in 1:numrates)#
	{#
	timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top#
	if (sum(TF) > 0)#
		{#
		spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]#
		} else {#
		TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num = min(c(num1, num2))#
		spRates[i] = obj$rtb$esSp[num]#
		exRates[i] = obj$rtb$esEx[num]		#
		} # END if (sum(TF) > 0)#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = m_slope * timebin + b_intercept#
		} # END if (sum(TF) > 0)#
	}#
#
# (currently estimated) diversity and rates#
diversities_rates_table = cbind(timebin_borders, spRates, exRates, spDiv)#
diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
names(diversities_rates_table) = c("timebin_borders", "spRates", "exRates", "spDiv")#
diversities_rates_table
timebin_borders
spRates
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
#
# calcLik_given_known_diversity#
#
# Make total list of timepoints for diversity curve likelihood#
timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
timebin_borders#
#
# Rates for each timebin#
numrates = length(timebin_borders)-1#
spRates = rep(NA, numrates)#
exRates = rep(NA, numrates)#
spDiv = rep(NA, numrates)#
for (i in 1:numrates)#
	{#
	timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top#
	if (sum(TF) > 0)#
		{#
		spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]#
		} else {#
		TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num = min(c(num1, num2))#
		spRates[i] = obj$rtb$esSp[num]#
		exRates[i] = obj$rtb$esEx[num]		#
		} # END if (sum(TF) > 0)#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = m_slope * timebin + b_intercept#
		} # END if (sum(TF) > 0)#
	}#
#
# (currently estimated) diversity and rates#
diversities_rates_table = cbind(timebin_borders[-length(timebin_borders)], spRates, exRates, spDiv)#
diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
names(diversities_rates_table) = c("timebin_borders", "spRates", "exRates", "spDiv")#
diversities_rates_table
round(diversities_rates_table$spDiv)
round(2.776923)
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
#
# calcLik_given_known_diversity#
#
# Make total list of timepoints for diversity curve likelihood#
timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
timebin_borders#
#
# Rates for each timebin#
numrates = length(timebin_borders)-1#
spRates = rep(NA, numrates)#
exRates = rep(NA, numrates)#
spDiv = rep(NA, numrates)#
for (i in 1:numrates)#
	{#
	timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top#
	if (sum(TF) > 0)#
		{#
		spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]#
		} else {#
		TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num = min(c(num1, num2))#
		spRates[i] = obj$rtb$esSp[num]#
		exRates[i] = obj$rtb$esEx[num]		#
		} # END if (sum(TF) > 0)#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = round(m_slope * timebin + b_intercept)#
		} # END if (sum(TF) > 0)#
	}#
#
# (currently estimated) diversity and rates#
diversities_rates_table = cbind(timebin_borders[-length(timebin_borders)], spRates, exRates, spDiv)#
diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
names(diversities_rates_table) = c("timebin_borders", "spRates", "exRates", "spDiv")#
diversities_rates_table
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R', chdir = TRUE)
diversities_rates_table = obj_to_diversities_rates_table(obj)#
diversities_rates_table
obj$rtb
mapply()
rate_timebins = c(0, 5, 10, 13)#
	diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
	obj = NULL#
	obj$tr0 = tr0								# typical APE phylo object, no root edge#
	obj$rootlength = rootlength					# length of edge below root node#
	obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
	obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
	obj$lnL = -10^12							# -1 trillion as default lnL#
	obj$rtb$esSp = c(0.3, 0.2, 0.1)#
	obj$rtb$esEx = c(0.1, 0.21, 0.3)#
	# Put in some species diversity points#
	obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
	obj$dtb$eNsp = obj$dtb$iNsp#
	obj$dtb$mNsp = 0#
	obj$dtb$xNsp = 10
# Make total list of timepoints for diversity curve likelihood#
	timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
	timebin_borders#
#
	# Rates for each timebin#
	numrates = length(timebin_borders)-1#
	spRates = rep(NA, numrates)#
	exRates = rep(NA, numrates)#
	spDiv = rep(NA, numrates)#
	for (i in 1:numrates)#
	{#
	timebin = timebin_borders[i]#
#
	TF = timebin == obj$rtb$top#
	if (sum(TF) > 0)#
		{#
		spRates[i] = obj$rtb$esSp[TF]#
		exRates[i] = obj$rtb$esEx[TF]#
		} else {#
		TF1 = timebin <= obj$rtb$top#
		num1 = min((1:length(obj$rtb$top))[TF1])#
		TF2 = timebin > obj$rtb$top#
		num2 = max((1:length(obj$rtb$top))[TF2])#
		num = min(c(num1, num2))#
		spRates[i] = obj$rtb$esSp[num]#
		exRates[i] = obj$rtb$esEx[num]		#
		} # END if (sum(TF) > 0)#
#
	# Diversity where there is a rate shift, but no curve data, #
	# is assumed to be a linear extrapolation of the curve#
	TF = timebin == obj$dtb$top#
	if (sum(TF) > 0)#
		{#
		spDiv[i] = obj$dtb$eNsp[TF]#
		} else {#
		TF1 = timebin <= obj$dtb$top#
		num1 = max((1:length(obj$dtb$top))[TF1])#
		TF2 = timebin > obj$dtb$top#
		num2 = min((1:length(obj$dtb$top))[TF2])#
		# Average the diversity based on linear extrapolation#
		# between the two closest measurements of diversity#
		numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
		denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
		# b = y - mx#
		m_slope = numerator / denominator#
		b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
		# Now predict diversity linearly#
		spDiv[i] = round(m_slope * timebin + b_intercept)#
		} # END if (sum(TF) > 0)#
	}#
#
	# (currently estimated) diversity and rates#
	diversities_rates_table = cbind(timebin_borders[-length(timebin_borders)], spRates, exRates, spDiv)#
	diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
	names(diversities_rates_table) = c("timebin_borders", "spRates", "exRates", "spDiv")#
	diversities_rates_table
mapply(drt = obj_to_diversities_rates_table(obj)#
drt)
drt = obj_to_diversities_rates_table(obj)#
drt
drt
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R', chdir = TRUE)
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt
# Object holding the stuff to get the likelihood of#
	rate_timebins = c(0, 5, 10, 13)#
	diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
	obj = NULL#
	obj$tr0 = tr0								# typical APE phylo object, no root edge#
	obj$rootlength = rootlength					# length of edge below root node#
	obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
	obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
	obj$lnL = -10^12							# -1 trillion as default lnL#
	obj$rtb$esSp = c(0.3, 0.2, 0.1)#
	obj$rtb$esEx = c(0.1, 0.21, 0.3)#
	# Put in some species diversity points#
	obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
	obj$dtb$eNsp = obj$dtb$iNsp#
	obj$dtb$mNsp = 0#
	obj$dtb$xNsp = 10
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R', chdir = TRUE)
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R', chdir = TRUE)
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt
rate_timebins = c(0, 5, 10, 13)#
	diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
	obj = NULL#
	obj$tr0 = tr0								# typical APE phylo object, no root edge#
	obj$rootlength = rootlength					# length of edge below root node#
	obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
	obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
	obj$lnL = -10^12							# -1 trillion as default lnL#
	obj$rtb$esSp = c(0.3, 0.2, 0.1)#
	obj$rtb$esEx = c(0.1, 0.21, 0.3)#
	# Put in some species diversity points#
	obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
	obj$dtb$eNsp = obj$dtb$iNsp#
	obj$dtb$mNsp = 0#
	obj$dtb$xNsp = 10
# Make total list of timepoints for diversity curve likelihood#
	timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
	timebin_borders#
	top = timebin_borders[-length(timebin_borders)]#
	bot = timebin_borders[-1]#
	# Rates for each timebin#
	numrates = length(timebin_borders)-1#
	spRates = rep(NA, numrates)#
	exRates = rep(NA, numrates)#
	spDivT = rep(NA, numrates)	# Diversity at the top#
	spDivB = rep(NA, numrates)	# Diversity at the bottom#
	for (i in 1:numrates)#
		{#
		timebin = timebin_borders[i]#
#
		TF = timebin == obj$rtb$top#
		if (sum(TF) > 0)#
			{#
			spRates[i] = obj$rtb$esSp[TF]#
			exRates[i] = obj$rtb$esEx[TF]#
			} else {#
			TF1 = timebin <= obj$rtb$top#
			num1 = min((1:length(obj$rtb$top))[TF1])#
			TF2 = timebin > obj$rtb$top#
			num2 = max((1:length(obj$rtb$top))[TF2])#
			num = min(c(num1, num2))#
			spRates[i] = obj$rtb$esSp[num]#
			exRates[i] = obj$rtb$esEx[num]		#
			} # END if (sum(TF) > 0)#
		# Diversity at the top#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$top#
		if (sum(TF) > 0)#
			{#
			spDivT[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivT[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		# Diversity at the bottom#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$bot#
		if (sum(TF) > 0)#
			{#
			spDivB[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivB[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		} # END for (i in 1:numrates)
i
timebin = timebin_borders[i]#
#
		TF = timebin == obj$rtb$top#
		if (sum(TF) > 0)#
			{#
			spRates[i] = obj$rtb$esSp[TF]#
			exRates[i] = obj$rtb$esEx[TF]#
			} else {#
			TF1 = timebin <= obj$rtb$top#
			num1 = min((1:length(obj$rtb$top))[TF1])#
			TF2 = timebin > obj$rtb$top#
			num2 = max((1:length(obj$rtb$top))[TF2])#
			num = min(c(num1, num2))#
			spRates[i] = obj$rtb$esSp[num]#
			exRates[i] = obj$rtb$esEx[num]		#
			} # END if (sum(TF) > 0)#
		# Diversity at the top#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$top#
		if (sum(TF) > 0)#
			{#
			spDivT[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivT[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		# Diversity at the bottom#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$bot#
		if (sum(TF) > 0)#
			{#
			spDivB[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivB[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)
i=1
timebin = timebin_borders[i]#
#
		TF = timebin == obj$rtb$top#
		if (sum(TF) > 0)#
			{#
			spRates[i] = obj$rtb$esSp[TF]#
			exRates[i] = obj$rtb$esEx[TF]#
			} else {#
			TF1 = timebin <= obj$rtb$top#
			num1 = min((1:length(obj$rtb$top))[TF1])#
			TF2 = timebin > obj$rtb$top#
			num2 = max((1:length(obj$rtb$top))[TF2])#
			num = min(c(num1, num2))#
			spRates[i] = obj$rtb$esSp[num]#
			exRates[i] = obj$rtb$esEx[num]		#
			} # END if (sum(TF) > 0)#
		# Diversity at the top#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$top#
		if (sum(TF) > 0)#
			{#
			spDivT[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivT[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		# Diversity at the bottom#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$bot#
		if (sum(TF) > 0)#
			{#
			spDivB[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivB[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)
timebin = timebin_borders[i]#
#
		TF = timebin == obj$rtb$top#
		if (sum(TF) > 0)#
			{#
			spRates[i] = obj$rtb$esSp[TF]#
			exRates[i] = obj$rtb$esEx[TF]#
			} else {#
			TF1 = timebin <= obj$rtb$top#
			num1 = min((1:length(obj$rtb$top))[TF1])#
			TF2 = timebin > obj$rtb$top#
			num2 = max((1:length(obj$rtb$top))[TF2])#
			num = min(c(num1, num2))#
			spRates[i] = obj$rtb$esSp[num]#
			exRates[i] = obj$rtb$esEx[num]		#
			} # END if (sum(TF) > 0)#
		# Diversity at the top#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$top#
		if (sum(TF) > 0)#
			{#
			spDivT[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivT[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)
TF = timebin == obj$dtb$bot
TF
obj$dtb$bot
timebin
# Make total list of timepoints for diversity curve likelihood#
	timebin_borders = sort(unique(c(obj$dtb$top, obj$rtb$top, obj$rtb$bot)))#
	timebin_borders#
	top = timebin_borders[-length(timebin_borders)]#
	bot = timebin_borders[-1]#
	# Rates for each timebin#
	numrates = length(timebin_borders)-1#
	spRates = rep(NA, numrates)#
	exRates = rep(NA, numrates)#
	spDivT = rep(NA, numrates)	# Diversity at the top#
	spDivB = rep(NA, numrates)	# Diversity at the bottom#
	for (i in 1:numrates)#
		{#
		timebin = timebin_borders[i]#
#
		TF = timebin == obj$rtb$top#
		if (sum(TF) > 0)#
			{#
			spRates[i] = obj$rtb$esSp[TF]#
			exRates[i] = obj$rtb$esEx[TF]#
			} else {#
			TF1 = timebin <= obj$rtb$top#
			num1 = min((1:length(obj$rtb$top))[TF1])#
			TF2 = timebin > obj$rtb$top#
			num2 = max((1:length(obj$rtb$top))[TF2])#
			num = min(c(num1, num2))#
			spRates[i] = obj$rtb$esSp[num]#
			exRates[i] = obj$rtb$esEx[num]		#
			} # END if (sum(TF) > 0)#
		# Diversity at the top#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		TF = timebin == obj$dtb$top#
		if (sum(TF) > 0)#
			{#
			spDivT[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivT[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		# Diversity at the bottom#
		# Diversity where there is a rate shift, but no curve data, #
		# is assumed to be a linear extrapolation of the curve#
		timebin = timebin_borders[i+1]#
		TF = timebin == obj$dtb$bot#
		if (sum(TF) > 0)#
			{#
			spDivB[i] = obj$dtb$eNsp[TF]#
			} else {#
			TF1 = timebin <= obj$dtb$top#
			num1 = max((1:length(obj$dtb$top))[TF1])#
			TF2 = timebin > obj$dtb$top#
			num2 = min((1:length(obj$dtb$top))[TF2])#
			# Average the diversity based on linear extrapolation#
			# between the two closest measurements of diversity#
			numerator = obj$dtb$eNsp[num2] - obj$dtb$eNsp[num1]#
			denominator = obj$dtb$top[num2] - obj$dtb$top[num1]#
			# b = y - mx#
			m_slope = numerator / denominator#
			b_intercept = obj$dtb$top[num2] - m_slope * obj$dtb$eNsp[num2]#
			# Now predict diversity linearly#
			spDivB[i] = round(m_slope * timebin + b_intercept)#
			} # END if (sum(TF) > 0)#
#
		} # END for (i in 1:numrates)#
#
	# (currently estimated) diversity and rates#
	# duration = dur#
	dur = bot - top#
	diversities_rates_table = cbind(top, bot, dur, spRates, exRates, spDivT, spDivB)#
	diversities_rates_table = as.data.frame(diversities_rates_table, stringsAsFactors=FALSE)#
	names(diversities_rates_table) = c("top", "bot", "dur", "spRates", "exRates", "spDivT", "spDivB")#
	diversities_rates_table
mapply(library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
precBits = 120#
mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=c(precBits=precBits))#
)
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
precBits = 120#
mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=c(precBits=precBits))
mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R', chdir = TRUE)
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")
mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))
sum(lnLs)
lnLs = mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))#
sum(lnLs)
LikShifts()
obj$rtb
obj$rtb$esSp
timebins
sort(unique(c(obj$rtb$top, obj$rtb$bot)))
########################################################
# Joint likelihood, BDrho process + fossil diversity#
########################################################
#
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
# Calculate the log-likelihood of the (current) assumed diversity curve#
precBits = 120#
lnLs = mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))#
lnL_diversity_curve = sum(lnLs)#
#
# Diversity table, add lnLs#
drt = cbind(drt, lnLs)#
#
# Calculate the log-likelihood of the tree under the rate shifts etc.#
#
# LikShifts2_from_obj#
# Set up the tree#
splittimes_table = getx(obj$tr, sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
timebins = sort(unique(c(obj$rtb$top, obj$rtb$bot)))#
timebins = timebins[-length(timebins)]#
lambda = obj$rtb$esSp#
mu = obj$rtb$esEx#
rho = obj$rtb$rho#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
########################################################
# Joint likelihood, BDrho process + fossil diversity#
########################################################
#
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
# Calculate the log-likelihood of the (current) assumed diversity curve#
precBits = 120#
lnLs = mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))#
lnL_diversity_curve = sum(lnLs)#
#
# Diversity table, add lnLs#
drt = cbind(drt, lnLs)#
#
# Calculate the log-likelihood of the tree under the rate shifts etc.#
#
# LikShifts2_from_obj#
# Set up the tree#
splittimes_table = getx(obj$tr, sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
timebins = sort(unique(c(obj$rtb$top, obj$rtb$bot)))#
timebins = timebins[-length(timebins)]#
lambda = obj$rtb$esSp#
mu = obj$rtb$esEx#
rho = obj$rtb$rho#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
########################################################
# Joint likelihood, BDrho process + fossil diversity#
########################################################
#
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
# Calculate the log-likelihood of the (current) assumed diversity curve#
precBits = 120#
lnLs = mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))#
lnL_diversity_curve = sum(lnLs)#
#
# Diversity table, add lnLs#
drt = cbind(drt, lnLs)#
#
# Calculate the log-likelihood of the tree under the rate shifts etc.#
#
# LikShifts2_from_obj#
# Set up the tree#
splittimes_table = getx(obj$tr, sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
timebins = sort(unique(c(obj$rtb$top, obj$rtb$bot)))#
timebins = timebins[-length(timebins)]#
lambda = obj$rtb$esSp#
mu = obj$rtb$esEx#
rho = obj$rtb$rho#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
########################################################
# Joint likelihood, BDrho process + fossil diversity#
########################################################
#
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifs_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
########################################################
# Calculate the likelihood, given known or #
# assumed diversity, and several rate shifts#
########################################################
# calcLik_given_known_diversity#
#
# drt = diversities_rates_table#
drt = obj_to_diversities_rates_table(obj)#
drt#
#
# Calculate the log-likelihood of the (current) assumed diversity curve#
precBits = 120#
lnLs = mapply(FUN=BD_spcounts_mpfr, time_t=drt$dur, a=drt$spDivB, b=drt$spDivT, lambda=drt$spRates, mu=drt$exRates, MoreArgs=list(precBits=precBits))#
lnL_diversity_curve = sum(lnLs)#
#
# Diversity table, add lnLs#
drt = cbind(drt, lnLs)#
#
# Calculate the log-likelihood of the tree under the rate shifts etc.#
#
# LikShifts2_from_obj#
# Set up the tree#
splittimes_table = getx(obj$tr, sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
timebins = sort(unique(c(obj$rtb$top, obj$rtb$bot)))#
timebins = timebins[-length(timebins)]#
lambda = obj$rtb$esSp#
mu = obj$rtb$esEx#
rho = obj$rtb$rho#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R')
lnL_of_obj(obj)
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifts_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
obj$lnL = -10^12							# -1 trillion as default lnL#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10
obj
########################################################
# Joint likelihood, BDrho process + fossil diversity#
########################################################
#
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifts_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
#
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
lnL_of_obj(obj)
optim()
rtb
obj$rtb
optim()
?control
?optim
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifts_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
lnL_of_obj(obj)
params = ratestable_to_params1(obj$rtb)#
params
params = ratestable_to_params1(obj$rtb)#
params#
#
optim_result = run_optim1(params=params, obj=obj, printflag=TRUE)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
params = ratestable_to_params1(obj$rtb)#
params#
#
optim_result = run_optim1(params=params, obj=obj, printflag=TRUE)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
params = ratestable_to_params1(obj$rtb)#
params#
#
optim_result = run_optim1(params=params, obj=obj, printflag=TRUE)
params = ratestable_to_params1(obj$rtb)		#
		names_params1 = paste0("esSp", 1:(length(params)/2))#
		names_params2 = paste0("esSp", ((length(params)/2)+1):(length(params)))#
		names_params = c(names_params1, names_params2)
names_params
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
params = ratestable_to_params1(obj$rtb)#
params#
#
optim_result = run_optim1(params=params, obj=obj, printflag=TRUE)
?LikShifts
? LikConstantn
set.seed(1)#
#
# First we simulate a tree, and then estimate the parameters for the tree:#
# Number of species#
nspecies <- 20#
# At time 1 and 2 in the past, we have a rate shift:#
time <- c(0,1,2)#
# Mass extinction intensities 0.5 at time 1 in past, 0.4 at time 2 in past. #
# Present day species are all sampled (rho[1]=1):#
rho <- c(1,0.5,0.4)#
# speciation rates (between t[i],t[i+1] we have speciation rate lambda[i]):#
lambda <- c(2,2,1)#
# extinction rates (between t[i],t[i+1] we have extinction rate mu[i]):#
mu <- c(1,1,0)#
# Simulation of a tree:#
tree<-sim.rateshift.taxa(nspecies,1,lambda,mu,frac=rho,times=time,complete=FALSE)#
# Extracting the speciation times x:#
x<-sort(getx(tree[[1]]),decreasing=TRUE)#
#
# When estimating the the rate shift times t based on branching times x, #
# we allow the shift times to be 0.6, 0.8, 1, 1.2, .. ,2.4:#
start <- 0.6#
end <- 2.4#
grid <- 0.2#
# We fix rho and estimate time, lambda, mu:#
res <- bd.shifts.optim(x,rho,grid,start,end)[[2]]#
res#
# res[[2]] tells us about the maximum likelihood estimate given one rate shift:#
# - log lik = 17.330862988.#
# rate shift at time 2.2.#
# turnover (extinction/speciation) = 0.186301549 more recent than 2.2,#
#     and = 0.939681843 more ancestral than 2.2.#
# net diversification (speciation-extinction) rate = 0.958947381 more recent than 2.2, #
#     and = 0.000100009 more ancestral than 2.2.#
#
#test if i shifts explain the tree significantly better than i-1 shifts, here i=1:#
i<-1#
test<-pchisq(2*(res[[i]][1]-res[[i+1]][1]),3)#
#if test>0.95 then i shifts is significantly better than i-1 shifts at a 5% error#
#
# We fix rho=1 and mu=0 and then estimate time, lambda:#
resyule <- bd.shifts.optim(x,rho,grid,start,end,yule=TRUE)#
resyule[[2]]#
# We estimate time, rho, lambda, mu:#
resrho <- bd.shifts.optim(x,rho,grid,start,end,ME=TRUE)
splittimes
bd.shifts.optim
?bd.shifts.optim
bd_shifts_optim2(x=splittimes, sampling=rho, timebins=timebins, maxitk=5, yule=FALSE, ME=FALSE, all=FALSE, posdiv=FALSE, miniall=c(0), survival=1, groups=groups)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/bd_shifts_optim2.R', chdir = TRUE)
bd_shifts_optim2(x=splittimes, sampling=rho, timebins=timebins, maxitk=5, yule=FALSE, ME=FALSE, all=FALSE, posdiv=FALSE, miniall=c(0), survival=1, groups=groups)
library(TreePar)
bd_shifts_optim2(x=splittimes, sampling=rho, timebins=timebins, maxitk=5, yule=FALSE, ME=FALSE, all=FALSE, posdiv=FALSE, miniall=c(0), survival=1, groups=groups)
TreePar:::bd.ME.optim
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/bd_shifts_optim2.R', chdir = TRUE)
bd_shifts_optim2(x=splittimes, sampling=rho, timebins=timebins, maxitk=5, yule=FALSE, ME=FALSE, all=FALSE, posdiv=FALSE, miniall=c(0), survival=1, groups=groups)
res = bd_shifts_optim2(x=splittimes, sampling=rho, timebins=timebins, maxitk=500, yule=FALSE, ME=FALSE, all=FALSE, posdiv=FALSE, miniall=c(0), survival=1, groups=groups)
res
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/bd_shifts_optim2.R', chdir = TRUE)
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/bd_shifts_optim2.R")
library(ape)#
library(BioGeoBEARS)#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/birthdeath_mpfr_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikeShifts_helper.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/rates_table_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/Lieberman_2001_equations_v1.R")#
source("/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/bd_shifts_optim2.R")
trstr = "(((Homo:6,Pan:6):1,Gorilla:7):5,Orang:12);"#
tr0 = read.tree(file="", text=trstr)#
plot(tr0); axisPhylo(); title("Hominoid tree")#
#
rootlength = 1#
tr = addroot(tr0, rootlength)#
tr$states = rep(1,4)#
#
# For some reason, this requires sersampling=1 to work#
branching.times(tr)#
splittimes_table = getx(tr,sersampling=1)#
splittimes_table = splittimes_table[splittimes_table[,"ttype"]==1,]#
splittimes = splittimes_table[,"times"]#
splittype = splittimes_table[,"ttype"]#
#
branching.times(tr0)#
splittimes0 = getx(tr0,sersampling=0)#
splittype0 = rep(1, length(splittimes0))#
splittimes#
splittype#
splittimes0#
splittype0#
#
timebins = c(0, 5)#
lambda = c(0.1, 0.2)#
mu = c(0.25, 0.15)#
rho = c(1, 1)#
posdiv = FALSE#
#
# If survival = 1, the likelihood is conditioned on survival #
# of the process (recommended). Otherwise survival = 0.#
survival = 1#
#
# For each tip, give a rho for that group#
# And, an age for that group#
# How does it tell the order?  Who the hell knows?#
# Ill assume it is tr$tip.label#
##
# If groups != 0: the first column of groups indicates the #
# age of higher taxa and the second column the number of #
# species in the higher taxa (each row in groups corresponds #
# to a leaf in the tree).#
clade_ages = c(0.95, 0.5, 1, 3)#
clade_rhos = c(1, 1/2, 1/3, 1/4)#
clade_rhos = c(1, 1, 1, 1)#
groups = cbind(clade_ages, clade_rhos)#
#
LikShifts2(splittimes=splittimes, timebins=timebins, lambda=lambda, mu=mu, rho=rho, posdiv=posdiv, survival=survival, groups=groups)#
# Try different values of precision#
precBits=120	# gets problematic at time_t=10#
#
time_t = 7#
a=100#
b=101#
lambda=0.3#
mu = 0.1#
(BD_spcounts_mpfr(time_t, a, b, lambda, mu, precBits))#
# Object holding the stuff to get the likelihood of#
rate_timebins = c(0, 5, 10, 13)#
diversity_timebins = c(0, 1, 2, 3, 4, 5, 13)#
obj = NULL#
obj$type = "both"							# both: combine the lnLs of the diversity curve and the tree#
											# diversity: just the lnL of the diversity curve#
											# tree: just the lnL of the tree#
obj$tr0 = tr0								# typical APE phylo object, no root edge#
obj$rootlength = rootlength					# length of edge below root node#
obj$posdiv = FALSE							# default, so that extinction can exceed speciation#
obj$survival = 1							# If survival = 1, the likelihood is conditioned on survival #
											# of the process (recommended). Otherwise survival = 0.#
obj$groups = groups#
#
obj$rtb = make_ratestable(timebins=rate_timebins)			# rtb = table of rates#
obj$dtb = make_diversities_table(timebins=diversity_timebins)	# dtb = table of diversities#
#
# Put in some rates#
obj$rtb$esSp = c(0.3, 0.2, 0.1)#
obj$rtb$esEx = c(0.1, 0.21, 0.3)#
#
# Put in some species diversity points#
obj$dtb$iNsp = c(1, 3, 4, 4, 3, 4, 4)#
obj$dtb$eNsp = obj$dtb$iNsp#
obj$dtb$mNsp = 0#
obj$dtb$xNsp = 10#
lnL_of_obj(obj)
obj2 = obj#
obj2$type = "tree"#
optim_result2 = run_optim1(params=params, obj=obj2, printflag=TRUE)
source('/drives/GDrive/__GDrive_projects/2016-07-14_diversity_curve/LikShifts2.R', chdir = TRUE)
obj2 = obj#
obj2$type = "tree"#
optim_result2 = run_optim1(params=params, obj=obj2, printflag=TRUE)
optim_result#
optim_result2
ratestable_to_params1(obj$rtb)
plot(tr0)
axisPhylo()
timebins
obj
plot(tr)
plot(tr0)
# Load the package (after installation, see above).#
library(optimx)         # You need to have some version of optimx available#
                        # as it is a BioGeoBEARS dependency; however, if you#
                        # don't want to use optimx, and use optim() (from R core) #
                        # you can set:#
                        # BioGeoBEARS_run_object$use_optimx = FALSE#
                        # ...everything should work either way -- NJM 2014-01-08#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
library(BioGeoBEARS)#
#
#########################################################
# TO GET THE OPTIMX/OPTIM FIX, AND THE UPPASS FIX, #
# SOURCE THE REVISED FUNCTIONS WITH THESE COMMANDS#
##
# CRUCIAL CRUCIAL CRUCIAL: #
# YOU HAVE TO RUN THE SOURCE COMMANDS AFTER #
# *EVERY TIME* YOU DO library(BioGeoBEARS). THE CHANGES ARE NOT "PERMANENT", #
# THEY HAVE TO BE MADE EACH TIME.  IF YOU ARE GOING TO BE OFFLINE, #
# YOU CAN DOWNLOAD EACH .R FILE TO YOUR HARD DRIVE AND REFER THE source()#
# COMMANDS TO THE FULL PATH AND FILENAME OF EACH FILE ON YOUR#
# LOCAL SYSTEM INSTEAD.#
#########################################################
library(BioGeoBEARS)#
source("http://phylo.wdfiles.com/local--files/biogeobears/cladoRcpp.R") # (needed now that traits model added; source FIRST!)#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_add_fossils_randomly_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_basics_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_calc_transition_matrices_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_classes_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_detection_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_DNA_cladogenesis_sim_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_extract_Qmat_COOmat_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_generics_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_models_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_on_multiple_trees_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_plots_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_readwrite_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_simulate_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_SSEsim_makePlots_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_SSEsim_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_stochastic_mapping_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_stratified_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_univ_model_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/calc_uppass_probs_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/calc_loglike_sp_v01.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/get_stratified_subbranch_top_downpass_likelihoods_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/runBSM_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/stochastic_map_given_inputs.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/summarize_BSM_tables_v1.R")#
source("http://phylo.wdfiles.com/local--files/biogeobears/BioGeoBEARS_traits_v1.R") # added traits model#
calc_loglike_sp = compiler::cmpfun(calc_loglike_sp_prebyte)    # crucial to fix bug in uppass calculations#
calc_independent_likelihoods_on_each_branch = compiler::cmpfun(calc_independent_likelihoods_on_each_branch_prebyte)#
    # slight speedup hopefully#
#
########################################################
# Local source()-ing method -- uses BioGeoBEARS sourceall() function #
# on a directory of .R files, so you don't have to type them out.#
# The directories here are on my machine, you would have to make a #
# directory, save the .R files there, and refer to them.#
##
# NOTE: it's best to source the "cladoRcpp.R" update first, to avoid warnings like this:#
###
## Note: possible error in 'rcpp_calc_anclikes_sp_COOweights_faster(Rcpp_leftprobs = tmpca_1, ': #
##         unused arguments (m = m, m_null_range = include_null_range, jts_matrix = jts_matrix) #
###
##
# TO USE: Delete or comment out the 'source("http://...")' commands above, and un-comment#
#              the below...#
#########################################################################
# Un-comment (and fix directory paths) to use:#
#library(BioGeoBEARS)#
#source("/drives/Dropbox/_njm/__packages/cladoRcpp_setup/cladoRcpp.R")#
#sourceall("/drives/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#calc_loglike_sp = compiler::cmpfun(calc_loglike_sp_prebyte)    # crucial to fix bug in uppass calculations#
#calc_independent_likelihoods_on_each_branch = compiler::cmpfun(calc_independent_likelihoods_on_each_branch_prebyte)#
#########################################################################
#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny:#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHLYIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
# 2. This is the same format used for C++ LAGRANGE geography files.#
# 3. All names in the geography file must match names in the phylogeny file.#
# 4. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
# 5. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; OMeara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = TRUE     # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }#
#
########################################################
# Run DEC+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; OMeara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = TRUE     # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DEC+J_M0_unconstrained_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDECj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDECj = res#
    }#
#
########################################################
# PDF plots#
########################################################
pdffn = "Psychotria_DEC_vs_DEC+J_M0_unconstrained_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - DEC#
########################################################
analysis_titletxt ="BioGeoBEARS DEC on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDEC#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - DECJ#
########################################################
analysis_titletxt ="BioGeoBEARS DEC+J on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDECj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()  # Turn off PDF#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr) # Plot it
plot_BioGeoBEARS_results()
areanames = names(tipranges@df)#
areanames#
#
include_null_range = TRUE#
#
states_list_0based_index = rcpp_areas_list_to_states_list(areas=areanames, maxareas=max_range_size, include_null_range=include_null_range)#
#
statenames = areas_list_to_states_list_new(areas=areanames, maxareas=max_range_size, include_null_range=include_null_range, split_ABC=FALSE)#
statenames#
#
colors_matrix = get_colors_for_numareas(length(areanames))#
colors_list_for_states = mix_colors_for_states(colors_matrix, states_list_0based_index, plot_null_range=include_null_range)#
colors_list_for_states
colors_matrix
library(TreeSim)
citation("TreeSim")
423-190
system("top")
system("kill -9 6037")
system("top")
system("ps -ef  |grep erminal")
system("jobs")
system("bg -h")
system("bg --help")
system("bg")
library(ape)
tr = read.tree(file="", text="(S_linnarssoni:11.651477545655087,(((((((B_porrectus:0.2409814680791893,((B_milleri:1.1429275303647737,B_tenuirugosus:0.21058290113360822):0.007153754794875233,B_beckeri:1.1458977731848048):2.214557632720923):0.32838554388466257,(B_solangeae:0.5226850870462005,B_bellevillensis:0.029401885314507936):0.5487624138298077):0.22159058288455924,B_kimmswickensis:0.5362577402161612):1.00073746953667,B_graffhami:0.1305192685123675):0.341171200145725,(B_holei:1.5003706514851576,B_billingsi:0.6224655657203151):0.422330272927665):0.36150870525733403,B_lenzi:3.6906191251340204E-4):4.074336467709827E-4,B_moundensis:4.20491694796965E-7):3.5560804301576514);")
tr
plot(tr)
tr$edge.length=NULL
tr
write.tree(tr, file="")
exp(10)
invgamma
library(pscl)
install.packages("pscl")
pcsl
pwd
library(pscl)
digamma
digamma()
densigamma(1,3,3)
x=seq(0,100,0.1)
x=seq(x,100,0.1)
x=seq(0,100,0.1)
densigamma(x,3,3)
densigamma(2,3,3)
densigamma(0,3,3)
x=seq(0.01,100,0.1)
densigamma(x,3,3)
plot(x, densigamma(x,3,3))
plot(x, densigamma(x,10,10))
plot(x, densigamma(x,1,1))
plot(x, densigamma(x,0.1,0.1))
plot(x, densigamma(x,0.01,0.01))
plot(x, densigamma(x,0.100,100))
plot(x, densigamma(x,100,100))
plot(x, densigamma(x,100,1))
plot(x, densigamma(x,1,100))
plot(x, densigamma(x,0.1,100))
xmlNode()
library(XML)
36.249744
36.249744-29.43
1.514425986+7
14.51442599+7
# Load the R libraries for dealing with phylogenies & XML#
library(XML)#
library(ape)   # for read.tree#
library(gdata) # for read.xls#
library(BioGeoBEARS) # for sourceall#
library(XLConnect)	# for readWorksheetFromFile#
#
######################################################
# Source BEASTmasteR code via the internet #
# (You could also save the R files locally and source() their locations on your hard disk. #
# This will be especially handy if your internet sucks. I have archived the R code in a #
# dated zipfile, see "Files" at the bottom of the page):#
######################################################
#
# On Nick's development computer:#
sourceall("/GDrive/__github/BEASTmasteR/R/")#
#
# source("/GDrive/__github/BEASTmasteR/R/basics_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/gts2012_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/make_generic_XML_prior_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/make_relativeMutationRate_operator_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/master_XML.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_clockrow_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_clocks_v2.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_morph_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_node_ages_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_run_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_OTUs_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_sequences_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_siteModels_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/parse_tree_strat_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/read_nexus_data2_v1.R")#
# source("/GDrive/__github/BEASTmasteR/R/tipdate_gaps_v1.R")#
#
# Online (you can also download each and source locally)#
# source("http://phylo.wdfiles.com/local--files/beastmaster/basics_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/gts2012_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/make_generic_XML_prior_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/make_relativeMutationRate_operator_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/master_XML.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_clockrow_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_clocks_v2.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_morph_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_node_ages_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_run_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_OTUs_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_sequences_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_siteModels_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/parse_tree_strat_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/read_nexus_data2_v1.R")#
# source("http://phylo.wdfiles.com/local--files/beastmaster/tipdate_gaps_v1.R")#
########################################################
# CHANGE SCRIPT HERE: USE YOUR OWN WORKING DIRECTORY#
# NOTE: Windows uses "\\" instead of "/"#
########################################################
#wd = "/drives/Dropbox/_njm/__packages/BEASTmasteR_permahelp/examples/ex_basic_venerid_morphDNA_v4/SABD_tipsVary_wOutg_v1/"#
#
wd = "/drives/GDrive/__GDrive_projects/2016-09-01_Adrian_Lam_Stigall/02_BEAST/Plaesiomys_v2simp_construct/"#
setwd(wd)#
#
# The name of the Excel settings file#
xlsfn = "settings_v1.xlsx"#
########################################################
# Double-check your working directory with getwd()#
########################################################
getwd()#
#
########################################################
# Double-check that you have the right files with list.files()#
########################################################
list.files()#
#
########################################################
# YOU SHOULD BE ABLE TO CUT-N-PASTE CODE FROM HERE DOWN#
# (But, do it line-by-line, so you can see what is going on!)#
########################################################
#
########################################################
# Required change to R settings (run every time)#
########################################################
# Turn off R's default stringsAsFactors silliness#
options(stringsAsFactors = FALSE)#
#
# When you have a starting tree named tree.newick, you could view it by un-commenting the code below:#
# trfn = "tree.newick"#
# tr = read.tree(trfn)#
# tr_table = prt(tr)#
# tr_table[,c("label","time_bp")]#
# names(tr_table)#
#
########################################################
# Setup the overall xml structure#
########################################################
xml = setup_master_XML()#
print_master_XML_section_headers(xml)#
########################################################
# Get the name of the species tree -- the main#
# target of the analysis#
########################################################
#tree_name = "shared_tree"#
treemodel_df = readWorksheetFromFile(xlsfn, sheet="treemodel", startRow=15)#
data_df = readWorksheetFromFile(xlsfn, sheet="data", startRow=15)#
data_df$use[isblank_TF(data_df$use)] = "yes"#
data_df = data_df[data_df$use == "yes",]#
tree_names = unique(c(treemodel_df$speciesTreeName, data_df$speciesTreeName))#
if (length(tree_names) > 1)#
	{#
	txt = "Error in BEASTmasteR: BEASTmasteR is not currently programed to accept more than one speciesTreeName. You have these:\n\n"#
	cat("\n\n")#
	cat(txt)#
	cat("treemodel_df$speciesTreeName:")#
	print(treemodel_df$speciesTreeName)#
	cat("\n\n")#
	cat("data_df$speciesTreeName:")#
	print(data_df$speciesTreeName)#
	cat("\n\n")#
	stop(txt)#
	} else {#
	tree_name = tree_names[1]#
	}#
if (is.null(tree_name))#
	{#
	tree_name = "shared_tree"#
	}#
tree_name#
#
#clockModel_name = "shared_clock"#
# Decide if this is a StarBeast2 analysis#
if (treemodel_df$treeModel[1] == "starBeast2")#
	{#
	StarBeast2_TF = TRUE#
	# This is required, if StarBeast2 is being used#
	taxonsets_df = readWorksheetFromFile(xlsfn, sheet="taxonsets", startRow=15)#
	# Error check#
	if (nrow(treemodel_df) > 1)#
		{#
		txt = paste0("STOP ERROR in check_for_starBeast2(): in worksheet 'treemodel', you have specified that treemodel_df$treeModel='starBeast2', meaning you want to do a starBeast2 analysis. However, starBeast2 assumes a simple birth-death model (constant rate, not skyline models), so you should only have one row in treemodel. However, you have ", nrow(treemodel_df), " rows.  Printing treemodel_df:")#
		cat("\n\n")#
		cat(txt)#
		cat("\n\n")#
		stop(txt)#
		}#
	} else {#
	StarBeast2_TF = FALSE#
	}#
# XML SECTION 1: Header and Beast2 Java class references / mappings #
# Done below#
#
# XML SECTION 2: Taxa and clade definitions (and tip-dates if desired) #
########################################################
# Get the OTUs from the Excel settings file#
########################################################
OTUs_df = readWorksheetFromFile(xlsfn, sheet="OTUs", startRow=15)#
head(OTUs_df)#
#
# Remove OTUs with "no" in "use" column of "OTUs" worksheet#
OTUs_df$use[isblank_TF(OTUs_df$use)] = "yes"#
keepTF = OTUs_df$use != "no"#
OTUs_df = OTUs_df[keepTF,]#
OTUs = OTUs_df$OTUs#
OTUs#
#
# Counting samples by time-bin (irrelevant if everything is living in the present)#
# (this is just a rough assessment of sampling-through-time -- delete if #
#  not interested)#
empirical_sampling_info = analyze_tipdates_for_gaps_in_sampling_EXAMPLES(OTUs_df)#
########################################################
# Write OTUs to ="list_of_OTUs"#
########################################################
#
# Not needed really#
tmpXML = make_XML_tipdate_priors(OTUs_df, min_precision=0.01, tree_name="shared_tree", xml=NULL)#
tmpXML$priors#
tmpXML$operators#
tmpXML$tracelog#
tmpXML$tipdatelog#
# Not needed really#
#
XML_list_of_OTUs = make_XMLs_for_OTUs(OTUs, OTU_idref=FALSE, StarBeast2_TF=StarBeast2_TF)#
list_of_OTUs_XML = make_XML_taxon_block(taxon_name="list_of_OTUs", XML_list_of_OTUs=XML_list_of_OTUs)#
list_of_OTUs_XML#
#
# Add to the list of taxa/clades (manually, as an example)#
xml$taxa = c(xml$taxa, list_of_OTUs_XML)#
########################################################
# Add taxonSets additional clades/taxa specified in "taxa"#
########################################################
taxa_df = readWorksheetFromFile(xlsfn, sheet="taxa", startRow=15)#
head(taxa_df)#
#
# Add the taxon groups (monophyletic clades and perhaps non-monophyletic groups of interest)#
xml = make_taxa_groups(taxa_df, OTUs=OTUs, xml=xml)#
#
# Add the genera if desired (for logging monophyly, if possible; if not, log ages)#
#genera = get_genera_from_OTUs(OTUs, mintaxa=2, split="_")#
#genera#
# Don't add genera to XML (you would only do it if you were SURE they were monophyletic)#
#xml = make_XML_for_genera_from_OTUs(xml, OTUs, mintaxa=2, split="_")#
#xml#
#
########################################################
# Add priors for the node constraints#
########################################################
nodes_df = readWorksheetFromFile(xlsfn, sheet="nodes", startRow=15)#
head(nodes_df)#
#
# Make the clade priors#
xml = make_cladePrior_XMLs(nodes_df, xml=xml, list_of_empty_taxa=xml$list_of_empty_taxa)#
#
# Add to the logs#
xml = make_cladePrior_logs(nodes_df, xml=xml, tree_name=tree_name, trace_or_screen="both", list_of_empty_taxa=xml$list_of_empty_taxa)#
#
# XML SECTION 3: Sequence alignments (e.g. DNA, morphology); filtered in later section to produce partitions #
seqs_df = readWorksheetFromFile(xlsfn, sheet="data", startRow=15)#
seqs_df = seqs_df[seqs_df$use == "yes", ]#
head(seqs_df)#
#
# See starting length of the XML#
orig_length_xml = length(xml)#
########################################################
# Add priors on the stem ages of terminal branches, if any#
# (specified in OTUs_df)#
########################################################
# # Default is no, so only pull out "yes"#
# stem_ages_df = OTUs_df[OTUs_df$stem_make_age_prior=="yes",]#
# for (i in 1:nrow(stem_ages_df))#
# 	{#
# 	dfline = stem_ages_df[i,]#
# 	param_name = paste0("stem_age_of_", dfline$OTUs)#
# 	stemXML = make_generic_XML_prior(dfline, colname_prefix="stem", param_name=param_name, header_scheme=1, stem=TRUE, distrib=NULL, param1=NULL, param2=NULL, tmp_offset=NULL, meanInRealSpace=NULL)#
# 	stemXML#
# 	}#
# stemXML#
########################################################
# Add relative priors, if any#
# (specified in OTUs_df and/or nodes_df)#
########################################################
xml = make_generic_difference_statistic(nodes_df=nodes_df, OTUs_df=OTUs_df, xml=xml)#
xml#
#################################################################
# PARSING NEXUS FILES WITH parse_datasets()#
#################################################################
##
# NOTE: THIS FUNCTION WILL PRODUCE A LOT OF SCREEN#
# OUTPUT, UNLESS YOU SET printall="none". THE SCREEN#
# OUTPUT IS GOOD, IT SHOWS YOU ALL THE REFORMATTING#
# OF THE CHARACTERS TO MAKE THEM ACCEPTABLE TO#
# BEAST. #
# #
# E.g., a particular character must have its#
# lowest state be state 0, it must not skip states#
# (no characters with only states 0, 3, and 4), and#
# the observed number of distinct character states#
# must match the number of claimed character states.#
# These are typically true for original datasets,#
# but after researchers cut out taxa, re-code#
# certain states, etc., sometimes it is no longer#
# true. The script counts the observed character#
# states, re-numbers them if needed, classifies them#
# by number of character states, and then reformats#
# for Beast2 (e.g., for a 2-state character, "?",#
# "-", "(0 1)", "(1 0)", "{0 1}", and {1 0} would#
# all be converted to "Z").#
# #
# For your own data, you may discover yet more weird#
# features of NEXUS data file formatting that I have#
# not coded for. Email them to the#
# beastmaster_package Google Group and I will try to#
# fix them.#
# #
# NEXUS files must be: (1) Simplified NEXUS format#
# (as exported from Mesquite), and (2) the taxon#
# names must have no spaces, quotes, or other weird#
# characters. Use underscores ("_") instead.#
# #
# Tracking characters in the NEXUS file: as a#
# double-check, just to make sure the data is not#
# being fundamentally changed, I have the script#
# write into XML: (1) the original morphology data#
# matrix, (2) the modified data matrix, and (3) the#
# character numbers (original numbers or indices#
# with each data section, depending) that have been#
# placed into each morphology data section. This#
# occurs because Beast2 requires that the 2-state,#
# 3-state, 4-state, etc. characters each be coded in#
# the XML in separate sections.#
#################################################################
# Run the parsing of NEXUS file(s)#
#
# Save old xml#
pre_parsing_xml = xml#
# xml = pre_parsing_xml#
#
# Once you've run parse_datasets successfully, you can#
# change runslow=TRUE for future runs to save time#
# (as long as you have data_XML.Rdata in the working#
# directory).#
runslow = TRUE#
data_XML_fn = "data_XML.Rdata"#
if (runslow)#
	{#
	data_XMLs = parse_datasets(seqs_df, xml=NULL, add_morphLength=TRUE, OTUs=OTUs, add_morphList=TRUE, printall="short", xlsfn=xlsfn, return_charsdf=TRUE, convert_ambiguous_to_IUPAC=FALSE)#
	save(data_XMLs, file=data_XML_fn)#
	} else {#
	# Loads to "data_XML"#
	load(file=data_XML_fn)#
	}#
#
# Tally the data#
dtf_list = data_XMLs$charsdf_list#
data_tally = tally_data(dtf_list=dtf_list, fns=NULL, dtf_list_fn=NULL, xlsfn=xlsfn, OTUs_df=NULL, taxa_df=NULL, nodes_df=NULL)#
xml$data_tally = data_tally#
#
# For StarBeast2, prune out sequences from specimenNames not listed in taxonsets_df#
# (no action taken when not a StarBeast2 analysis)#
data_XML = prune_seqs_based_on_taxonsets(data_XML=data_XMLs$data_XML, taxonsets_df=taxonsets_df, StarBeast2_TF=StarBeast2_TF)#
data_XMLs$data_XML = data_XML#
#
#data_XMLs[[1]][3]#
# If you have problems, read the help paragraphs above, #
# carefully look at the messages printed to screen, the E R R O R#
# messages, and carefully look at your input NEXUS file.#
# #
# It can also help to run read_nexus_data2 by itself:#
# E.g. get first used NEXUS file in 'data' worksheet:#
##
# Un-comment to run:#
# nexus_filename_to_read = seqs_df$filename[seqs_df$use==TRUE][1]#
# read_nexus_data2(file=nexus_filename_to_read, check_ambig_chars=TRUE, convert_ambiguous_to=NULL, printall="short", convert_ambiguous_to_IUPAC=FALSE) #
#
# Show the length of each data matrix#
data_XMLs$dataset_lengths_df#
#
# Show characters with <2 morphological states#
data_XMLs$chars_wLT_2_states_df_list#
#
# Show the stats#
data_XMLs$morphstats#
#
# Show the number of data matrices#
length(data_XMLs$charsdf_list)#
# Size of matrix #1#
if (length(data_XMLs$charsdf_list) > 0)#
	{#
	data_XMLs$charsdf_list[[1]]#
	data_XMLs$charsdf_list[[1]][1:5,1:5]#
	}#
#charslist = read_nexus_data2(file=seqs_df$filename[1], check_ambig_chars=TRUE, convert_ambiguous_to=NULL, printall="short", convert_ambiguous_to_IUPAC=FALSE) #
#
########################################################
# Continue with converting morphology#
########################################################
xml$sequences = c(xml$sequences, data_XMLs$data_XML)#
xml$misc = c(xml$misc, data_XMLs$misc_XML)#
xml$sitemodels = c(xml$sitemodels, data_XMLs$sitemodels_XML)#
xml$state = c(xml$state, data_XMLs$state_XML)#
xml$priors = c(xml$priors, data_XMLs$prior_XML)#
xml$likes = c(xml$likes, data_XMLs$likes_XMLs)#
xml$operators = c(xml$operators, data_XMLs$operator_XMLs)#
xml$tracelog = c(xml$tracelog, data_XMLs$tracelog_XMLs)#
xml$screenlog = c(xml$screenlog, data_XMLs$screenlog_XMLs)#
#
xml$morphLengths = data_XMLs$morphLengths#
xml$morphList = data_XMLs$morphList#
xml$dataset_lengths_df = data_XMLs$dataset_lengths_df#
xml$morphList #
# The number of (used!) characters#
# of each morphology DATASET (not partition)#
morphLengths = xml$morphLengths#
morphLengths#
#
# The number of (used!) characters in each morphology "partition" (section)#
morphList = xml$morphList#
sum(xml$morphList$numchars)#
morphList#
#
# Check that xml changed:#
orig_length_xml#
length(xml)#
#
# XML SECTION 4: Partitions #
# (filters applied to the sequence alignments produce partitions)#
#
# For non-morphology datasets, extract partitions from the alignments#
xml = make_partitions_XML(seqs_df, xml=xml, add_partitionLength=TRUE, dataset_lengths_df=NULL)#
xml$partitions#
#
partitionLengths = xml$partitionLengths_df$partitionLengths#
partitionLengths#
#
########################################################
# Add the tip-dates (assume age = 0 if none)#
# All blanks/NAs are converted to 0#
########################################################
OTUs = OTUs_df$OTUs[OTUs_df$use=="yes"]#
if (StarBeast2_TF == FALSE)#
	{#
	tipdates = OTUs_df$tipdate#
#
	# Get the alignment that will serve as a source of OTUs to reference with "@" #
	# in the tipdates 'taxa' tag#
	alignment_name_w_taxa = pick_a_partitionName_for_taxa_list(seqs_df=seqs_df, morphList=morphList)#
#
	# Make the tipdates#
	OTUs_df$use[isblank_TF(OTUs_df$use)] = "yes"#
	XML_tipdates = make_XML_tipdates(name="tipDates", OTUs_df, alignment_name_w_taxa=alignment_name_w_taxa, backward=TRUE, xml=NULL)#
#
	# Add to the list of taxa/clades (here, manually, just to show the process)#
	xml$taxa = c(xml$taxa, XML_tipdates)#
	xml$taxa#
#
	########################################################
	# Add a taxonSet for the fossils, if there are any#
	########################################################
	xml = add_fossils_taxon_to_xml(OTUs, tipdates, xml)#
#
	########################################################
	# Add tipdate uncertainty, sampling, and logging, if desired#
	########################################################
	xml = make_XML_tipdate_priors(OTUs_df, min_precision=0.01, tree_name=tree_name, xml=xml)#
	} else {#
	if ((exists("alignment_name_w_taxa") == FALSE) || (is.null(alignment_name_w_taxa) == TRUE) )#
		{#
		taxa_list = taxa_list_for_starBEAST(xlsfn=xlsfn, sheet="taxonsets")#
		}#
	} # END if (StarBeast2_TF == FALSE)#
# XML SECTION 5: Miscellaneous#
# (none yet)#
######################################################
# SECTIONS 6-7: Partitions and clock models#
######################################################
# Load the sequence partitions and their clocks;#
# Remember to subset to just the ones where use=yes#
seqs_df = readWorksheetFromFile(xlsfn, sheet="data", startRow=15)#
seqs_df = seqs_df[seqs_df$use != "no", ]#
#
# Get the number of taxa#
ntaxa = length(OTUs_df$OTUs)#
#
# XML SECTION 6: Site Models (sequence/morphology evolution models for each partition) #
xml = parse_DNA_AA_siteModels(seqs_df, xml=xml, tree_name=tree_name, StarBeast2_TF=StarBeast2_TF)#
xml$dataset_lengths_df#
# XML SECTION 7: Shared clock model (relaxed ucld currently; also, the strict clock would be where stdev=~0) #
#
# Get the names of each clock (usually there is just 1)#
clockModel_names = get_clock_names(seqs_df)#
i=1#
for (i in 1:length(clockModel_names))#
	{#
	# Get the name of the clock model#
	clockModel_name = clockModel_names[i]#
	if (StarBeast2_TF==TRUE)#
		{#
		# Get corresponding name of the gene tree (for StarBeast2 analysis)#
		# (and the dataset)#
		TF = seqs_df$clockModel_name==clockModel_name#
		gene_tree_name = seqs_df$geneTreeName[TF][1]#
		dataset_name = seqs_df$datasetName[TF][1]#
		TF2 = xml$dataset_lengths_df$dataset_names == dataset_name#
		ntaxa = as.numeric(xml$dataset_lengths_df$dataset_ntaxa[TF2][1])#
		# StarBeast2 analysis#
		gene_tree_name = seqs_df$geneTreeName[i]#
		xml = define_a_shared_clock(seqs_df, ntaxa=ntaxa, clockModel_name=clockModel_name, tree_name=gene_tree_name, xml=xml)#
		} else {#
		# Regular Beast2 analysis#
		tree_name = tree_name#
		xml = define_a_shared_clock(seqs_df, ntaxa, clockModel_name=clockModel_name, tree_name=tree_name, xml=xml)#
		}#
	# New, more flexible#
	# define_a_shared_clock(seqs_df, ntaxa, clockModel_name=clockModel_name, tree_name=tree_name, xml=NULL)#
	# Old#
	#xml = define_logNormal_shared_clock(clockModel_name=clockModel_name, tree_name=tree_name, ntaxa=ntaxa, xml=xml)#
	}#
xml$clock#
xml$clock[1:10]#
xml$clock[(length(xml$clock)-10):length(xml$clock)]#
length(xml$clock[5:length(xml$clock)]) / 6 	# 6 items per clock#
# Do the XML for relativeMutationRates#
# (the relative rate of each partition)#
#
# For multiple clocks: Put this in a loop with #
# different partitionLengths (DNA) and morphLengths (morphology)#
# for each clock#
partitionLengths_df = xml$partitionLengths_df#
morphLengths = xml$morphLengths#
#
clockModel_names = unique(seqs_df$clockModel_name)#
clockModel_name=clockModel_names[1]#
make_relativeMutationRate_operator(seqs_df, partitionLengths_df=partitionLengths_df, morphLengths=morphLengths, clockModel_name=clockModel_name, relrate_suffix = "", xml=NULL)#
#
for (i in 1:length(clockModel_names))#
	{#
	clockModel_name = clockModel_names[i]#
	xml = make_relativeMutationRate_operator(seqs_df, partitionLengths_df=partitionLengths_df, morphLengths=morphLengths, clockModel_name=clockModel_name, relrate_suffix = "", xml=xml)#
	} #
xml$operators#
########################################################
# Make relative mutation rates, ONLY for the situation#
# where there are multiple partitions #
########################################################
#
# XML for morphology models, priors, likelihoods#
if (!is.null(morphList))#
	{#
	xml = make_Beast2_morph_models(morphList, morphRate_name="morph_relRate", morphGamma_name="morph_gammaShape", clockModel_name=clockModel_name, tree_name=tree_name, xml=xml)#
	#xml = make_Beast2_morph_models(morphList[1:4,], morphRate_name="morph_relRate", morphGamma_name="morph_gammaShape", clockModel_name=clockModel_name, tree_name=tree_name, xml=xml)#
	# NJM: for 2nd morph matrix#
	#xml = make_Beast2_morph_models(morphList[5:7,], morphRate_name="morphSl_relRate", morphGamma_name="morphSl_gammaShape", clockModel_name=clockModel_name, tree_name=tree_name, xml=xml)#
	}#
# Get the logEvery for the speciesTree logger#
run_df = readWorksheetFromFile(xlsfn, sheet="run", startRow=15)#
run_df#
# XML SECTION 8: Shared tree model (Yule, Birth-Death (BD), Birth-Death Skyline (BDSKY), etc.) #
treemodel_df = readWorksheetFromFile(xlsfn, sheet="treemodel", startRow=15)#
#
# Does the dataset include continuous characters?  The XML for the tree needs to #
# be different depending on whether or not this is so!  See: #
# https://groups.google.com/forum/#!topic/beast-users/7KFzWd4PVeQ#
TF = seqs_df$use != "no"#
if (("continuous" %in% seqs_df$type[TF]) == TRUE)#
	{#
	XML_mod_for_cont_chars = TRUE#
	} else {#
	XML_mod_for_cont_chars = FALSE#
	}
alignment_name_w_taxa = pick_a_partitionName_for_taxa_list(seqs_df=seqs_df, morphList=morphList)#
#
	#xmltmp = make_BDSKY_model(treemodel_df, tree_name=tree_name, clockModel_name=clockModel_name, alignment_name_w_taxa=alignment_name_w_taxa, tipDates_id="tipDates", xml=NULL, XML_mod_for_cont_chars=FALSE)#
	# Make the trstr via "construct"#
	trstr = NULL#
	startingTree_option = treemodel_df$starting_tree[isblank_TF(treemodel_df$starting_tree)==FALSE]
# OTUs#
if (is.null(OTUs_df) && !is.null(xlsfn))#
	{#
	OTUs_df = readWorksheetFromFile(xlsfn, sheet="OTUs", startRow=15)#
	} else {#
	if (is.null(OTUs_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have OTUs_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
#
prune_OTUs = TRUE#
if (prune_OTUs == TRUE)#
	{#
	# Remove OTUs with "no" in "use" column of "OTUs" worksheet#
	OTUs_df$use[isblank_TF(OTUs_df$use)] = "yes"#
	keepTF = OTUs_df$use != "no"#
	OTUs_df = OTUs_df[keepTF,]#
	OTUs = OTUs_df$OTUs#
	OTUs#
	}#
# Taxa groups (list of OTUs in clades)#
if (is.null(taxa_df) && !is.null(xlsfn))#
	{#
	taxa_df = readWorksheetFromFile(xlsfn, sheet="taxa", startRow=15)#
	} else {#
	if (is.null(taxa_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have taxa_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
#
# Error check:#
if (any(isblank_TF(taxa_df$mono)))#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): The column taxa_df$mono has blank cells. All cells must be either 'yes' or 'no'. Printing taxa_df$mono so you can inspect it."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	cat("taxa_df$mono:\n")#
	print(taxa_df$mono)#
	stop(stoptxt)#
	}#
#
# Filter taxa_df by "use"#
# AND by monophyletic (we will ignore non-monophyletic date constraints for now)#
taxa_df$use[isblank_TF(taxa_df$use)] = "yes"#
keepTF1 = taxa_df$use != "no"#
keepTF2 = taxa_df$use == "yes"#
keepTF = (keepTF1 + keepTF2) == 2#
taxa_df = taxa_df[keepTF,]#
#
# Filter to only #
# Taxa groups (list of OTUs in clades)#
if (is.null(taxa_df) && !is.null(xlsfn))#
	{#
	nodes_df = readWorksheetFromFile(xlsfn, sheet="nodes", startRow=15)#
	} else {#
	if (is.null(nodes_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have nodes_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
# Gather clade names, remove empty clades#
names_of_groups = names(taxa_df)#
# Check names#
keepTF = rep(TRUE, times=length(names_of_groups))#
for (i in 1:length(names_of_groups))#
	{#
	items = taxa_df[,names_of_groups[i]]#
	items2 = remove_blanks_NAs_etc(items)#
#
	# Keep if the column has one or more non-blank taxa#
	if (length(items2) < 1)#
		{#
		keepTF[i] = FALSE#
		} # END if (length(items2) < 1)#
	} # END for (i in 1:length(names_of_groups))#
#
names_of_groups = names_of_groups[keepTF]#
# Error check for unique groups#
if (length(names_of_groups) != length(unique(names_of_groups)))#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): The names of your clades have to all be unique, but they are not. Printing the names of the clades."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	print(names_of_groups)#
	cat("\n")#
	stop(stoptxt)#
	} # END if (length(names_of_groups) != length(unique(names_of_groups)))#
# Keep a list of the taxa which end up EMPTY -- we will CUT #
# these from the priors list (or else it causes an error)#
list_of_empty_taxa = NULL#
list_of_clades = list()#
keepTF = rep(TRUE, length(names_of_groups))#
for (i in 1:length(names_of_groups))#
	{#
	groupname = names_of_groups[i]#
	# Check if the groupname is used in the subset nodes_df#
	if ((groupname %in% nodes_df$Taxon) == FALSE)#
		{#
		# Skip it#
		keepTF[i] = FALSE#
		next()#
		}#
	items = taxa_df[,groupname]#
	items2 = remove_blanks_NAs_etc(items)#
#
	# Filter out names not found in OTUs; throw warning for each#
	if (is.null(OTUs) == FALSE)#
		{#
		TF = items2 %in% OTUs#
		if (sum(TF) == 0)#
			{#
			txt = paste0("WARNING in make_taxa_groups(): None of the taxa names in '", groupname, "' are found in overall list in 'OTUs'. The group '", groupname, "' is being left out of the XML.")#
			cat("\n")#
			cat(txt)#
			cat("\n")#
			warning(txt)#
			cat("\n")#
			list_of_empty_taxa = c(list_of_empty_taxa, groupname)#
			# Skip to next#
			next()#
			} # END if (sum(TF) == 0)#
		items_being_removed = items2[TF == FALSE]#
		if (length(items_being_removed) > 0)#
			{#
			for (j in 1:length(items_being_removed))#
				{#
				txt = paste0("'", items_being_removed[j], "' is missing from overall 'OTUs' so is being cut from '", groupname, "'.")#
				cat("\n")#
				cat(txt)#
				cat("\n")#
				warning(txt)#
				cat("\n")#
				} # END for (j in 1:length(items_being_removed))#
			} # END if (length(items_being_removed) > 0)#
		# Subset the OTUs#
		items2 = items2[TF]#
		} # END if (is.null(OTUs) == FALSE)#
	list_of_clades = c(list_of_clades, list(items2))#
	}#
list_of_clades#
names_of_groups = names_of_groups[keepTF]#
#
# Order the clades from smallest to largest#
lengths = sapply(X=list_of_clades, FUN=length)#
clade_order_by_size = order(lengths)#
list_of_clades = list_of_clades[clade_order_by_size]#
names_of_groups = names_of_groups[clade_order_by_size]#
names(list_of_clades) = names_of_groups#
#
# List of which subclades go in which#
list_of_subclades_of_each_clade = list()#
for (i in 1:length(names_of_groups))#
	{#
	cmdtxt = paste0("list_of_subclades_of_each_clade$", names_of_groups[i], " = '", names_of_groups[i], "'")#
	eval(parse(text=cmdtxt))#
	}#
#
# For each clade, check that it doesn't contradict larger clades#
for (i in 1:(length(list_of_clades)-1))#
	{#
	for (j in (i+1):length(list_of_clades))#
		{#
		smaller_clade_OTUs_in_larger_TF = list_of_clades[[i]] %in% list_of_clades[[j]]#
		# Record the match, if it occurs#
		if (sum(smaller_clade_OTUs_in_larger_TF) == length(smaller_clade_OTUs_in_larger_TF))#
			{#
			list_of_subclades_of_each_clade[[j]] = c(list_of_subclades_of_each_clade[[j]], names_of_groups[i])#
			}#
		if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
			{#
			if (sum(smaller_clade_OTUs_in_larger_TF) != 0)#
				{#
				stoptxt = "STOP ERROR in construct_starting_tree(). You have a contradiction between clades that you have specified should be monophyletic -- but the first clade only partially fits inside the second clade. Printing the offending clades for your inspection."#
#
				cat("\n\n")#
				cat(stoptxt)#
				cat("\n\n")#
				cat("Clade #1: ", names_of_groups[i], ", printing list of OTUs:")#
				cat("\n")#
				print(list_of_clades[[i]])#
				cat("\n")#
				cat("Clade #2: ", names_of_groups[j], ", printing list of OTUs:")#
				cat("\n")#
				print(list_of_clades[[j]])#
				cat("\n")#
				stop(stoptxt)#
				} # END if (sum(smaller_clade_OTUs_in_larger_TF) != 0)#
			} # END if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
		} # END for (j in (i+1):length(list_of_clades))#
	} # END for (i in 1:(length(list_of_clades)-1))#
list_of_subclades_of_each_clade#
# List of tips in each subclade, after collapsing 1 level down#
list_of_clades_collapsed = list_of_clades#
#
# Collapse tipnames that go in a subclade#
for (j in (length(list_of_clades)):2)#
	{#
	for (i in (j-1):1)#
		{#
		smaller_clade_OTUs_in_larger_TF = list_of_clades_collapsed[[i]] %in% list_of_clades_collapsed[[j]]#
		# Record the match, if it occurs#
		if (sum(smaller_clade_OTUs_in_larger_TF) == length(smaller_clade_OTUs_in_larger_TF))#
			{#
			bigger_OTUs_list = list_of_clades_collapsed[[j]]#
			smaller_list = list_of_clades_collapsed[[i]]#
			OTUs_to_collapse_TF = bigger_OTUs_list %in% smaller_list#
			bigger_OTUs_list = bigger_OTUs_list[OTUs_to_collapse_TF == FALSE]#
			bigger_OTUs_list = c(bigger_OTUs_list, names_of_groups[i])#
			list_of_clades_collapsed[[j]] = bigger_OTUs_list#
			} # END if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
		} # END for (j in (i+1):length(list_of_clades))#
	} # END for (i in 1:(length(list_of_clades)-1))#
#
list_of_clades_collapsed#
#
# Make subtrees, from smallest to biggest#
list_of_subtrees = list()#
for (j in 1:length(list_of_clades_collapsed))#
	{#
	tmpOTUs = list_of_clades_collapsed[[j]]#
	tmptr = rtree(n=length(tmpOTUs), rooted=TRUE, tip.label=tmpOTUs, br=runif, min=0.00001, max=0.00001)#
	list_of_subtrees[[j]] = tmptr#
	}#
list_of_subtrees#
# Go backwards through the list, and paste in the subtrees#
master_tr = list_of_subtrees[[length(list_of_subtrees)]]#
for (j in length(list_of_subtrees):1)#
	{#
	tmp_tips = master_tr$tip.label#
	tips_that_are_clades_TF = (tmp_tips %in% OTUs) == FALSE#
	if (sum(tips_that_are_clades_TF) == 0)#
		{#
		next()#
		}#
	tmp_tips_to_expand = tmp_tips[tips_that_are_clades_TF]#
	# Bind each subtree#
	for (i in 1:length(tmp_tips_to_expand))#
		{#
		# Find the clade number#
		TF = names(list_of_clades) == tmp_tips_to_expand[i]#
		cladename_num = (1:length(names(list_of_clades)))[TF]#
		# Find the tip number in the growing master tree#
		tipnum_TF = master_tr$tip.label == tmp_tips_to_expand[i]#
		tipnum = (1:length(master_tr$tip.label))[tipnum_TF]#
		# Insert into the master tree#
		master_tr = bind.tree(x=master_tr, y=list_of_subtrees[[cladename_num]], where=tipnum, position=0.000005, interactive=FALSE)#
		# Drop the old tip label; read to/from Newick#
		master_tr = drop.tip(phy=master_tr, tip=tmp_tips_to_expand[i])#
		master_tr = read.tree(file="", text=write.tree(phy=master_tr, file=""))#
		}#
	}#
#
master_tr#
plot(master_tr)#
axisPhylo()#
ntips = length(master_tr$tip.label)#
#
# Error check: assembled tree has the same number of tips as OTUs#
problem = FALSE#
if (ntips != length(OTUs))#
	{#
	problem = 1#
	}#
OTUs_in_master_tr_TF = OTUs %in% master_tr$tip.label#
if (sum(OTUs_in_master_tr_TF) != length(OTUs_in_master_tr_TF))#
	{#
	problem = 2#
	}#
master_tr_in_OTUs_TF =  master_tr$tip.label %in% OTUs#
if (sum(master_tr_in_OTUs_TF) != length(master_tr_in_OTUs_TF))#
	{#
	problem = 3#
	}#
if (problem != FALSE)#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): Something went wrong in assembling the topology of the starting tree. The OTUs in 'master_tr$tip.label' and in 'OTUs' do not match. Printing them for inspection."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	cat("(Problem #", problem, ")", sep="")#
	cat("\n\n")#
	cat("master_tr$tip.label:")#
	cat("\n")#
	cat(sort(master_tr$tip.label), sep=", ")#
	cat("\n")#
#
	cat("OTUs:")#
	cat("\n")#
	cat(sort(OTUs), sep=", ")#
	cat("\n")#
#
	stop(stoptxt)#
	}#
# Now the branchlengths are all ultra-short. Add enough to get the #
# internal nodes below the deepest tip.#
ntips = length(master_tr$tip.label)#
tipnums = 1:ntips#
oldest_tipage = max(OTUs_df$tipdate)#
tr_table = prt(master_tr, printflag=FALSE, get_tipnames=TRUE)#
current_tipages = tr_table$time_bp[tipnums]#
current_tipages#
#
times_to_add = oldest_tipage - current_tipages#
#
edgenums_of_tips = tr_table$parent_br[tipnums]#
master_tr$edge.length[edgenums_of_tips] = master_tr$edge.length[edgenums_of_tips] + times_to_add#
#
plot(master_tr)#
axisPhylo()#
#
# Shorten the tip-dated terminal branches#
current_tipages = tr_table$time_bp[tipnums]#
current_tipages
OTUs
tipnames = master_tr$tip.label
tipnames
match(OTUs, table=tipnames)
match()
tipnames
OTUs[match(x=OTUs, table=tipnames)]
tipnames = master_tr$tip.label#
OTU_tipages = OTUs_df$tipdate[match(x=tipnames, table=OTUs)]#
OTUs[match(x=tipnames, table=OTUs)]
# Match OTUs to tree tiplabel order#
tipnames = master_tr$tip.label#
OTU_tipages = OTUs_df$tipdate[match(x=tipnames, table=OTUs)]#
OTUs[match(x=tipnames, table=OTUs)]#
#
# Changes to dates#
changes_to_tip_brlens = current_tipages - OTU_tipages#
changes_to_tip_brlens
# OTUs#
if (is.null(OTUs_df) && !is.null(xlsfn))#
	{#
	OTUs_df = readWorksheetFromFile(xlsfn, sheet="OTUs", startRow=15)#
	} else {#
	if (is.null(OTUs_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have OTUs_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
#
prune_OTUs = TRUE#
if (prune_OTUs == TRUE)#
	{#
	# Remove OTUs with "no" in "use" column of "OTUs" worksheet#
	OTUs_df$use[isblank_TF(OTUs_df$use)] = "yes"#
	keepTF = OTUs_df$use != "no"#
	OTUs_df = OTUs_df[keepTF,]#
	OTUs = OTUs_df$OTUs#
	OTUs#
	}#
# Taxa groups (list of OTUs in clades)#
if (is.null(taxa_df) && !is.null(xlsfn))#
	{#
	taxa_df = readWorksheetFromFile(xlsfn, sheet="taxa", startRow=15)#
	} else {#
	if (is.null(taxa_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have taxa_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
#
# Error check:#
if (any(isblank_TF(taxa_df$mono)))#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): The column taxa_df$mono has blank cells. All cells must be either 'yes' or 'no'. Printing taxa_df$mono so you can inspect it."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	cat("taxa_df$mono:\n")#
	print(taxa_df$mono)#
	stop(stoptxt)#
	}#
#
# Filter taxa_df by "use"#
# AND by monophyletic (we will ignore non-monophyletic date constraints for now)#
taxa_df$use[isblank_TF(taxa_df$use)] = "yes"#
keepTF1 = taxa_df$use != "no"#
keepTF2 = taxa_df$use == "yes"#
keepTF = (keepTF1 + keepTF2) == 2#
taxa_df = taxa_df[keepTF,]#
#
# Filter to only #
# Taxa groups (list of OTUs in clades)#
if (is.null(taxa_df) && !is.null(xlsfn))#
	{#
	nodes_df = readWorksheetFromFile(xlsfn, sheet="nodes", startRow=15)#
	} else {#
	if (is.null(nodes_df) == TRUE)#
		{#
		stoptxt = "STOP ERROR in construct_starting_tree(): Your inputs to this function have nodes_df=NULL and xlsfn=NULL. At least one of these must be non-null."#
		cat("\n\n")#
		cat(stoptxt)#
		cat("\n\n")#
		stop(stoptxt)#
		}#
	} # END if (is.null(OTUs_df) && !is.null(xlsfn))#
# Gather clade names, remove empty clades#
names_of_groups = names(taxa_df)#
# Check names#
keepTF = rep(TRUE, times=length(names_of_groups))#
for (i in 1:length(names_of_groups))#
	{#
	items = taxa_df[,names_of_groups[i]]#
	items2 = remove_blanks_NAs_etc(items)#
#
	# Keep if the column has one or more non-blank taxa#
	if (length(items2) < 1)#
		{#
		keepTF[i] = FALSE#
		} # END if (length(items2) < 1)#
	} # END for (i in 1:length(names_of_groups))#
#
names_of_groups = names_of_groups[keepTF]#
# Error check for unique groups#
if (length(names_of_groups) != length(unique(names_of_groups)))#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): The names of your clades have to all be unique, but they are not. Printing the names of the clades."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	print(names_of_groups)#
	cat("\n")#
	stop(stoptxt)#
	} # END if (length(names_of_groups) != length(unique(names_of_groups)))#
# Keep a list of the taxa which end up EMPTY -- we will CUT #
# these from the priors list (or else it causes an error)#
list_of_empty_taxa = NULL#
list_of_clades = list()#
keepTF = rep(TRUE, length(names_of_groups))#
for (i in 1:length(names_of_groups))#
	{#
	groupname = names_of_groups[i]#
	# Check if the groupname is used in the subset nodes_df#
	if ((groupname %in% nodes_df$Taxon) == FALSE)#
		{#
		# Skip it#
		keepTF[i] = FALSE#
		next()#
		}#
	items = taxa_df[,groupname]#
	items2 = remove_blanks_NAs_etc(items)#
#
	# Filter out names not found in OTUs; throw warning for each#
	if (is.null(OTUs) == FALSE)#
		{#
		TF = items2 %in% OTUs#
		if (sum(TF) == 0)#
			{#
			txt = paste0("WARNING in make_taxa_groups(): None of the taxa names in '", groupname, "' are found in overall list in 'OTUs'. The group '", groupname, "' is being left out of the XML.")#
			cat("\n")#
			cat(txt)#
			cat("\n")#
			warning(txt)#
			cat("\n")#
			list_of_empty_taxa = c(list_of_empty_taxa, groupname)#
			# Skip to next#
			next()#
			} # END if (sum(TF) == 0)#
		items_being_removed = items2[TF == FALSE]#
		if (length(items_being_removed) > 0)#
			{#
			for (j in 1:length(items_being_removed))#
				{#
				txt = paste0("'", items_being_removed[j], "' is missing from overall 'OTUs' so is being cut from '", groupname, "'.")#
				cat("\n")#
				cat(txt)#
				cat("\n")#
				warning(txt)#
				cat("\n")#
				} # END for (j in 1:length(items_being_removed))#
			} # END if (length(items_being_removed) > 0)#
		# Subset the OTUs#
		items2 = items2[TF]#
		} # END if (is.null(OTUs) == FALSE)#
	list_of_clades = c(list_of_clades, list(items2))#
	}#
list_of_clades#
names_of_groups = names_of_groups[keepTF]#
#
# Order the clades from smallest to largest#
lengths = sapply(X=list_of_clades, FUN=length)#
clade_order_by_size = order(lengths)#
list_of_clades = list_of_clades[clade_order_by_size]#
names_of_groups = names_of_groups[clade_order_by_size]#
names(list_of_clades) = names_of_groups#
#
# List of which subclades go in which#
list_of_subclades_of_each_clade = list()#
for (i in 1:length(names_of_groups))#
	{#
	cmdtxt = paste0("list_of_subclades_of_each_clade$", names_of_groups[i], " = '", names_of_groups[i], "'")#
	eval(parse(text=cmdtxt))#
	}#
#
# For each clade, check that it doesn't contradict larger clades#
for (i in 1:(length(list_of_clades)-1))#
	{#
	for (j in (i+1):length(list_of_clades))#
		{#
		smaller_clade_OTUs_in_larger_TF = list_of_clades[[i]] %in% list_of_clades[[j]]#
		# Record the match, if it occurs#
		if (sum(smaller_clade_OTUs_in_larger_TF) == length(smaller_clade_OTUs_in_larger_TF))#
			{#
			list_of_subclades_of_each_clade[[j]] = c(list_of_subclades_of_each_clade[[j]], names_of_groups[i])#
			}#
		if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
			{#
			if (sum(smaller_clade_OTUs_in_larger_TF) != 0)#
				{#
				stoptxt = "STOP ERROR in construct_starting_tree(). You have a contradiction between clades that you have specified should be monophyletic -- but the first clade only partially fits inside the second clade. Printing the offending clades for your inspection."#
#
				cat("\n\n")#
				cat(stoptxt)#
				cat("\n\n")#
				cat("Clade #1: ", names_of_groups[i], ", printing list of OTUs:")#
				cat("\n")#
				print(list_of_clades[[i]])#
				cat("\n")#
				cat("Clade #2: ", names_of_groups[j], ", printing list of OTUs:")#
				cat("\n")#
				print(list_of_clades[[j]])#
				cat("\n")#
				stop(stoptxt)#
				} # END if (sum(smaller_clade_OTUs_in_larger_TF) != 0)#
			} # END if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
		} # END for (j in (i+1):length(list_of_clades))#
	} # END for (i in 1:(length(list_of_clades)-1))#
list_of_subclades_of_each_clade#
# List of tips in each subclade, after collapsing 1 level down#
list_of_clades_collapsed = list_of_clades#
#
# Collapse tipnames that go in a subclade#
for (j in (length(list_of_clades)):2)#
	{#
	for (i in (j-1):1)#
		{#
		smaller_clade_OTUs_in_larger_TF = list_of_clades_collapsed[[i]] %in% list_of_clades_collapsed[[j]]#
		# Record the match, if it occurs#
		if (sum(smaller_clade_OTUs_in_larger_TF) == length(smaller_clade_OTUs_in_larger_TF))#
			{#
			bigger_OTUs_list = list_of_clades_collapsed[[j]]#
			smaller_list = list_of_clades_collapsed[[i]]#
			OTUs_to_collapse_TF = bigger_OTUs_list %in% smaller_list#
			bigger_OTUs_list = bigger_OTUs_list[OTUs_to_collapse_TF == FALSE]#
			bigger_OTUs_list = c(bigger_OTUs_list, names_of_groups[i])#
			list_of_clades_collapsed[[j]] = bigger_OTUs_list#
			} # END if (sum(smaller_clade_OTUs_in_larger_TF) != length(smaller_clade_OTUs_in_larger_TF))#
		} # END for (j in (i+1):length(list_of_clades))#
	} # END for (i in 1:(length(list_of_clades)-1))#
#
list_of_clades_collapsed#
#
# Make subtrees, from smallest to biggest#
list_of_subtrees = list()#
for (j in 1:length(list_of_clades_collapsed))#
	{#
	tmpOTUs = list_of_clades_collapsed[[j]]#
	tmptr = rtree(n=length(tmpOTUs), rooted=TRUE, tip.label=tmpOTUs, br=runif, min=0.00001, max=0.00001)#
	list_of_subtrees[[j]] = tmptr#
	}#
list_of_subtrees#
# Go backwards through the list, and paste in the subtrees#
master_tr = list_of_subtrees[[length(list_of_subtrees)]]#
for (j in length(list_of_subtrees):1)#
	{#
	tmp_tips = master_tr$tip.label#
	tips_that_are_clades_TF = (tmp_tips %in% OTUs) == FALSE#
	if (sum(tips_that_are_clades_TF) == 0)#
		{#
		next()#
		}#
	tmp_tips_to_expand = tmp_tips[tips_that_are_clades_TF]#
	# Bind each subtree#
	for (i in 1:length(tmp_tips_to_expand))#
		{#
		# Find the clade number#
		TF = names(list_of_clades) == tmp_tips_to_expand[i]#
		cladename_num = (1:length(names(list_of_clades)))[TF]#
		# Find the tip number in the growing master tree#
		tipnum_TF = master_tr$tip.label == tmp_tips_to_expand[i]#
		tipnum = (1:length(master_tr$tip.label))[tipnum_TF]#
		# Insert into the master tree#
		master_tr = bind.tree(x=master_tr, y=list_of_subtrees[[cladename_num]], where=tipnum, position=0.000005, interactive=FALSE)#
		# Drop the old tip label; read to/from Newick#
		master_tr = drop.tip(phy=master_tr, tip=tmp_tips_to_expand[i])#
		master_tr = read.tree(file="", text=write.tree(phy=master_tr, file=""))#
		}#
	}#
#
master_tr#
plot(master_tr)#
axisPhylo()#
ntips = length(master_tr$tip.label)#
#
# Error check: assembled tree has the same number of tips as OTUs#
problem = FALSE#
if (ntips != length(OTUs))#
	{#
	problem = 1#
	}#
OTUs_in_master_tr_TF = OTUs %in% master_tr$tip.label#
if (sum(OTUs_in_master_tr_TF) != length(OTUs_in_master_tr_TF))#
	{#
	problem = 2#
	}#
master_tr_in_OTUs_TF =  master_tr$tip.label %in% OTUs#
if (sum(master_tr_in_OTUs_TF) != length(master_tr_in_OTUs_TF))#
	{#
	problem = 3#
	}#
if (problem != FALSE)#
	{#
	stoptxt = "STOP ERROR in construct_starting_tree(): Something went wrong in assembling the topology of the starting tree. The OTUs in 'master_tr$tip.label' and in 'OTUs' do not match. Printing them for inspection."#
	cat("\n\n")#
	cat(stoptxt)#
	cat("\n\n")#
	cat("(Problem #", problem, ")", sep="")#
	cat("\n\n")#
	cat("master_tr$tip.label:")#
	cat("\n")#
	cat(sort(master_tr$tip.label), sep=", ")#
	cat("\n")#
#
	cat("OTUs:")#
	cat("\n")#
	cat(sort(OTUs), sep=", ")#
	cat("\n")#
#
	stop(stoptxt)#
	}#
# Now the branchlengths are all ultra-short. Add enough to get the #
# internal nodes below the deepest tip.#
ntips = length(master_tr$tip.label)#
tipnums = 1:ntips#
oldest_tipage = max(OTUs_df$tipdate)#
tr_table = prt(master_tr, printflag=FALSE, get_tipnames=TRUE)#
current_tipages = tr_table$time_bp[tipnums]#
current_tipages#
#
times_to_add = oldest_tipage - current_tipages#
#
edgenums_of_tips = tr_table$parent_br[tipnums]#
master_tr$edge.length[edgenums_of_tips] = master_tr$edge.length[edgenums_of_tips] + times_to_add#
#
plot(master_tr)#
axisPhylo()#
#
# Shorten the tip-dated terminal branches#
current_tipages = tr_table$time_bp[tipnums]#
current_tipages#
#
# Match OTUs to tree tiplabel order#
tipnames = master_tr$tip.label#
OTU_tipages = OTUs_df$tipdate[match(x=tipnames, table=OTUs)]#
OTUs[match(x=tipnames, table=OTUs)]#
#
# Changes to dates#
changes_to_tip_brlens = current_tipages - OTU_tipages#
changes_to_tip_brlens#
#
master_tr$edge.length[edgenums_of_tips] = master_tr$edge.length[edgenums_of_tips] + changes_to_tip_brlens#
plot(master_tr)#
axisPhylo()
list_of_subtrees
list_of_clades
names_of_groups
trtable
tr_table
i=1
subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtr_table$tip.label)#
		tipnums = 1:ntips
tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
#
		# Match OTUs to tree tiplabel order#
		OTUs_in_subtree_TF = OTUs %in% tipnames#
		subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]#
		subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]
subtr_table
tipnums
subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtr_table$tip.label)#
		tipnums = 1:ntips
tipnums
subtree
prt(subtree, printflag=FALSE, get_tipnames=FALSE)
ntips = length(subtree$tip.label)#
		tipnums = 1:ntips
tipnums
tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages
OTUs_in_subtree_TF = OTUs %in% tipnames
OTUs_in_subtree_TF
subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]
subtree_OTUs
subtree_tipdates
subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]
# Changes to dates#
		edgenums_of_tips = subtr_table$parent_br[tipnums]#
		changes_to_tip_brlens = current_tipages - subtree_OTUs_tipages#
		changes_to_tip_brlens#
#
		subtree$edge.length[edgenums_of_tips] = subtree$edge.length[edgenums_of_tips] + changes_to_tip_brlens
current_tipages
subtree_OTUs_tipages
subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtree$tip.label)#
		tipnums = 1:ntips#
#
		tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
#
		# Match OTUs to tree tiplabel order#
		OTUs_in_subtree_TF = OTUs %in% tipnames#
		subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]#
		subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]#
		max_age = max(OTUs_df$tipdate)#
#
		# Changes to dates#
		edgenums_of_tips = subtr_table$parent_br[tipnums]#
		changes_to_tip_brlens = max_age - current_tipages#
		changes_to_tip_brlens
plot(subtree)
axisPhylo()
subtree$edge.length[edgenums_of_tips] = subtree$edge.length[edgenums_of_tips] + changes_to_tip_brlens#
		subtree#
		plot(subtree)#
		axisPhylo()
subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtree$tip.label)#
		tipnums = 1:ntips#
#
		tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
#
		# Match OTUs to tree tiplabel order#
		OTUs_in_subtree_TF = OTUs %in% tipnames#
		subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]#
		subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]#
		max_age = max(subtree_OTUs_tipages)#
#
		# Changes to dates#
		edgenums_of_tips = subtr_table$parent_br[tipnums]#
		changes_to_tip_brlens = max_age - current_tipages#
		changes_to_tip_brlens#
#
		subtree$edge.length[edgenums_of_tips] = subtree$edge.length[edgenums_of_tips] + changes_to_tip_brlens#
		subtree#
		plot(subtree)#
		axisPhylo()
desired_node_age
if (tolower(nodes_df$distribution[i]) == "normal")#
			{#
			desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "uniform")#
			{#
			desired_node_age = (nodes_df$param1[i] + nodes_df$param2[i])/2 + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "lognormal")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = exp(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}#
		if (tolower(nodes_df$distribution[i]) == "exponential")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = 1/(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}
desired_node_age
i
nodes_df$distribution[i]
nodes_df$offset[isblank_TF(nodes_df$offset)] = 0
if (tolower(nodes_df$distribution[i]) == "normal")#
			{#
			desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "uniform")#
			{#
			desired_node_age = (nodes_df$param1[i] + nodes_df$param2[i])/2 + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "lognormal")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = exp(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}#
		if (tolower(nodes_df$distribution[i]) == "exponential")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = 1/(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}
desired_node_age
# OK, for this subtree, get the tip ages#
		subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtree$tip.label)#
		tipnums = 1:ntips#
#
		tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages
subtr_table
subtr_table
# OK, for this subtree, get the tip ages#
		subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtree$tip.label)#
		tipnums = 1:ntips#
#
		tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
		# Match OTUs to tree tiplabel order#
		OTUs_in_subtree_TF = OTUs %in% tipnames#
		subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]#
		oldest_tip_age = max(subtree_tipdates)#
		# Match the OTU table tipdates to the subtree table#
		subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]#
		# If the desired node age is less than oldest_tip_age, re-set to tip age + 1%#
		if (desired_node_age <= oldest_tip_age)#
			{#
			desired_node_age = oldest_tip_age * 1.01#
			}#
		# Multiply all branchlengths to get the root at the right age#
		tree_height = max(subtr_table$time_bp)#
		subtree$edge.length = subtree$edge.length * desired_node_age / tree_height#
		# Now edit the tip dates (even if this creates negative branch lengths)#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
		# Changes to dates#
		edgenums_of_tips = subtr_table$parent_br[tipnums]#
		changes_to_tip_brlens = subtree_OTUs_tipages - current_tipages#
		changes_to_tip_brlens
plot(subtree)
desired_node_ages = NULL#
for (i in 1:length(names_of_groups))#
	{#
	if (nodes_df$make_age_prior[i] != "yes")#
		{#
		next()#
		}#
	if (nodes_df$make_age_prior[i] == "yes")#
		{#
		if (tolower(nodes_df$distribution[i]) == "normal")#
			{#
			desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "uniform")#
			{#
			desired_node_age = (nodes_df$param1[i] + nodes_df$param2[i])/2 + nodes_df$offset[i]#
			}#
		if (tolower(nodes_df$distribution[i]) == "lognormal")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = exp(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}#
		if (tolower(nodes_df$distribution[i]) == "exponential")#
			{#
			if (nodes_df$meanInRealSpace[i] == "yes")#
				{#
				desired_node_age = nodes_df$param1[i] + nodes_df$offset[i]#
				}#
			if (nodes_df$meanInRealSpace[i] == "no")#
				{#
				meanval = 1/(nodes_df$param1[i])#
				desired_node_age = meanval + nodes_df$offset[i]#
				}#
			}#
		# OK, for this subtree, get the tip ages#
		subtree = list_of_subtrees[[i]]#
		subtr_table = prt(subtree, printflag=FALSE, get_tipnames=FALSE)#
		ntips = length(subtree$tip.label)#
		tipnums = 1:ntips#
#
		tipnames = subtr_table$label[tipnums]#
		current_tipages = subtr_table$time_bp[tipnums]#
		current_tipages#
		# Match OTUs to tree tiplabel order#
		OTUs_in_subtree_TF = OTUs %in% tipnames#
		subtree_OTUs = OTUs[OTUs_in_subtree_TF]#
		subtree_tipdates = OTUs_df$tipdate[OTUs_in_subtree_TF]#
		oldest_tip_age = max(subtree_tipdates)#
		# Match the OTU table tipdates to the subtree table#
		subtree_OTUs[match(x=tipnames, table=subtree_OTUs)]#
		subtree_OTUs_tipages = subtree_tipdates[match(x=tipnames, table=subtree_OTUs)]#
		# If the desired node age is less than oldest_tip_age, re-set to tip age + 1%#
		if (desired_node_age <= oldest_tip_age)#
			{#
			desired_node_age = oldest_tip_age * 1.01#
			}#
		desired_node_ages = (desired_node_ages, desired_node_age)#
		}#
	}#
desired_node_ages
